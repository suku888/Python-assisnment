{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "1: What is Anomaly Detection? Explain its types (point, contextual, and\n",
        "collective anomalies) with examples.\n",
        "\n",
        "Anomaly Detection\n",
        "Definition\n",
        "\n",
        "Anomaly Detection (or outlier detection) is the process of identifying data points, events, or observations that deviate significantly from the normal pattern of the dataset.\n",
        "\n",
        "Such anomalies often indicate fraud, network intrusions, equipment failures, or rare events.\n",
        "\n",
        "It is widely used in domains like finance, cybersecurity, healthcare, IoT, and e-commerce.\n",
        "\n",
        "Types of Anomalies\n",
        "1. Point Anomalies\n",
        "\n",
        "Definition: A single data point is significantly different from the rest of the data.\n",
        "\n",
        "Example:\n",
        "\n",
        "A customer suddenly spends ₹10,00,000 in one transaction, while their usual spending is under ₹10,000.\n",
        "\n",
        "A temperature sensor showing 100°C when all other readings are around 25°C.\n",
        "\n",
        "2. Contextual Anomalies\n",
        "\n",
        "Definition: A data point is anomalous in a specific context, but may be normal in another.\n",
        "\n",
        "Requires contextual information like time, location, or conditions.\n",
        "\n",
        "Example:\n",
        "\n",
        "A temperature of 30°C is normal in summer but anomalous in winter.\n",
        "\n",
        "A network bandwidth spike at night (when usage is usually low) could be suspicious, but not during office hours.\n",
        "\n",
        "3. Collective Anomalies\n",
        "\n",
        "Definition: A group (collection) of data points is anomalous together, even if individual points are not.\n",
        "\n",
        "Detected when patterns or sequences deviate from expected behavior.\n",
        "\n",
        "Example:\n",
        "\n",
        "Multiple small fraudulent credit card transactions from different locations in a short time.\n",
        "\n",
        "A sudden burst of error logs on a server, indicating a cyberattack or system crash.\n",
        "\n",
        "✅ In summary\n",
        "\n",
        "Point Anomalies: Single unusual data points.\n",
        "\n",
        "Contextual Anomalies: Normal data points in one context, abnormal in another.\n",
        "\n",
        "Collective Anomalies: A set of data points that collectively form an unusual pattern.\n",
        "\n",
        "Anomaly detection helps organizations spot fraud, detect system failures early, and improve security."
      ],
      "metadata": {
        "id": "ycfFhgKebVhd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2: Compare Isolation Forest, DBSCAN, and Local Outlier Factor in terms of\n",
        "their approach and suitable use cases.\n",
        "\n",
        "Comparison of Anomaly Detection Methods\n",
        "Algorithm\tApproach\tStrengths\tLimitations\tSuitable Use Cases\n",
        "Isolation Forest\tRandomly partitions data using decision trees. Anomalies are isolated faster since they require fewer splits.\t- Works well on high-dimensional data.\n",
        "- Efficient and scalable to large datasets.\n",
        "- Does not assume distribution of data.\t- May not capture local anomalies well.\n",
        "- Sensitive to contamination parameter (expected % of anomalies).\t- Credit card fraud detection.\n",
        "- Network intrusion detection.\n",
        "- Large-scale e-commerce datasets.\n",
        "DBSCAN\tDensity-based clustering: points in low-density areas (not belonging to any cluster) are anomalies.\t- Can find anomalies as noise points.\n",
        "- Detects arbitrary-shaped clusters.\n",
        "- No need to specify number of clusters.\t- Sensitive to parameters (ε, MinPts).\n",
        "- Struggles with high-dimensional data.\t- Geospatial anomaly detection (e.g., unusual GPS locations).\n",
        "- Customer segmentation with outlier detection.\n",
        "- Sensor data anomalies.\n",
        "Local Outlier Factor (LOF)\tCompares local density of a point with its neighbors. A point with significantly lower density than neighbors is an outlier.\t- Detects local anomalies well.\n",
        "- No global distribution assumption.\t- Computationally expensive for large datasets.\n",
        "- Sensitive to k (number of neighbors).\t- Fraud detection where anomalies are context-dependent.\n",
        "- Detecting abnormal user behavior in small datasets.\n",
        "- IoT sensor monitoring.\n",
        "✅ In Summary\n",
        "\n",
        "Isolation Forest → Best for large, high-dimensional datasets.\n",
        "\n",
        "DBSCAN → Best when anomalies appear as noise outside dense clusters.\n",
        "\n",
        "LOF → Best for local/contextual anomalies where density varies across the dataset."
      ],
      "metadata": {
        "id": "ddBFn_aAbV10"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3: What are the key components of a Time Series? Explain each with one\n",
        "example.\n",
        "\n",
        "\n",
        "Key Components of a Time Series\n",
        "\n",
        "A time series is a sequence of observations recorded at regular time intervals. To analyze and forecast it, we break it into four main components:\n",
        "\n",
        "1. Trend (T)\n",
        "\n",
        "Definition: The long-term upward or downward movement in the data over time.\n",
        "\n",
        "Example:\n",
        "\n",
        "The steady increase in e-commerce sales over several years due to digital adoption.\n",
        "\n",
        "Stock market index showing long-term growth.\n",
        "\n",
        "2. Seasonality (S)\n",
        "\n",
        "Definition: Regular, repeating patterns in the data at fixed intervals (daily, weekly, monthly, yearly).\n",
        "\n",
        "Example:\n",
        "\n",
        "Ice cream sales peak every summer and drop in winter.\n",
        "\n",
        "Electricity demand increases every evening.\n",
        "\n",
        "3. Cyclical (C)\n",
        "\n",
        "Definition: Fluctuations that occur over longer, irregular time periods (not strictly periodic), often influenced by business or economic cycles.\n",
        "\n",
        "Example:\n",
        "\n",
        "Economic recessions and booms affect car sales and housing markets.\n",
        "\n",
        "Oil prices fluctuating with global demand-supply cycles.\n",
        "\n",
        "4. Irregular/Residual/Noise (I)\n",
        "\n",
        "Definition: Random, unpredictable variations in the data that cannot be explained by trend, seasonality, or cycle.\n",
        "\n",
        "Example:\n",
        "\n",
        "A sudden spike in airline cancellations due to a storm.\n",
        "\n",
        "A factory shutdown due to unexpected power failure.\n",
        "\n",
        "✅ In summary\n",
        "\n",
        "Trend: Long-term direction (e.g., rising stock prices).\n",
        "\n",
        "Seasonality: Short-term regular patterns (e.g., holiday shopping spikes).\n",
        "\n",
        "Cyclical: Long-term business/economic fluctuations (e.g., recession impact).\n",
        "\n",
        "Irregular: Random unexpected events (e.g., natural disasters)."
      ],
      "metadata": {
        "id": "5Akq9aljbWBj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "4: Define Stationary in time series. How can you test and transform a\n",
        "non-stationary series into a stationary one?\n",
        "\n",
        "Stationarity in Time Series\n",
        "Definition\n",
        "\n",
        "A time series is stationary if its statistical properties such as mean, variance, and autocovariance remain constant over time.\n",
        "\n",
        "In a stationary series, patterns do not depend on the time at which the series is observed.\n",
        "\n",
        "Most forecasting models (e.g., ARIMA) assume stationarity for reliable predictions.\n",
        "\n",
        "Why Important?\n",
        "\n",
        "Stationarity simplifies modeling.\n",
        "\n",
        "Non-stationary series may have trends, seasonality, or varying variance, which can mislead forecasts.\n",
        "\n",
        "How to Test Stationarity?\n",
        "\n",
        "Visual Inspection\n",
        "\n",
        "Plot the series. If it shows trend, seasonality, or changing variance, it is likely non-stationary.\n",
        "\n",
        "Summary Statistics\n",
        "\n",
        "Check rolling mean and variance over time. If they change, the series is non-stationary.\n",
        "\n",
        "Statistical Tests\n",
        "\n",
        "ADF (Augmented Dickey-Fuller) Test:\n",
        "\n",
        "Null hypothesis (H₀): Series has a unit root (non-stationary).\n",
        "\n",
        "If p-value < 0.05 → reject H₀ → series is stationary.\n",
        "\n",
        "KPSS (Kwiatkowski–Phillips–Schmidt–Shin) Test:\n",
        "\n",
        "Null hypothesis: Series is stationary.\n",
        "\n",
        "If p-value < 0.05 → reject H₀ → series is non-stationary.\n",
        "\n",
        "How to Transform a Non-Stationary Series into Stationary?\n",
        "\n",
        "Differencing\n",
        "\n",
        "Subtract current observation from previous observation.\n",
        "\n",
        "Example:\n",
        "𝑌\n",
        "𝑡\n",
        "′\n",
        "=\n",
        "𝑌\n",
        "𝑡\n",
        "−\n",
        "𝑌\n",
        "𝑡\n",
        "−\n",
        "1\n",
        "Y\n",
        "t\n",
        "′\n",
        "\t​\n",
        "\n",
        "=Y\n",
        "t\n",
        "\t​\n",
        "\n",
        "−Y\n",
        "t−1\n",
        "\t​\n",
        "\n",
        "\n",
        "Removes trend and stabilizes mean.\n",
        "\n",
        "Detrending\n",
        "\n",
        "Fit and remove the trend (e.g., regression or moving average).\n",
        "\n",
        "Deseasonalizing\n",
        "\n",
        "Divide or subtract seasonal component from the series.\n",
        "\n",
        "Transformations\n",
        "\n",
        "Apply log, square root, or Box-Cox transformations to stabilize variance.\n",
        "\n",
        "Example: Stock prices → apply log to reduce heteroscedasticity.\n",
        "\n",
        "✅ In summary\n",
        "\n",
        "Stationary series: Constant mean, variance, autocovariance over time.\n",
        "\n",
        "Test: Visual inspection, ADF/KPSS tests.\n",
        "\n",
        "Make stationary: Differencing, detrending, deseasonalizing, transformations."
      ],
      "metadata": {
        "id": "uweDaCKrdWl0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "5: Differentiate between AR, MA, ARIMA, SARIMA, and SARIMAX models in\n",
        "terms of structure and application\n",
        "\n",
        "\n",
        "Difference between AR, MA, ARIMA, SARIMA, and SARIMAX Models\n",
        "\n",
        "Time series forecasting uses different statistical models depending on patterns in the data.\n",
        "\n",
        "1. AR (Autoregressive Model)\n",
        "\n",
        "Structure:\n",
        "\n",
        "Current value depends on its past values (lags).\n",
        "\n",
        "𝑌\n",
        "𝑡\n",
        "=\n",
        "𝑐\n",
        "+\n",
        "𝜙\n",
        "1\n",
        "𝑌\n",
        "𝑡\n",
        "−\n",
        "1\n",
        "+\n",
        "𝜙\n",
        "2\n",
        "𝑌\n",
        "𝑡\n",
        "−\n",
        "2\n",
        "+\n",
        "⋯\n",
        "+\n",
        "𝜖\n",
        "𝑡\n",
        "Y\n",
        "t\n",
        "\t​\n",
        "\n",
        "=c+ϕ\n",
        "1\n",
        "\t​\n",
        "\n",
        "Y\n",
        "t−1\n",
        "\t​\n",
        "\n",
        "+ϕ\n",
        "2\n",
        "\t​\n",
        "\n",
        "Y\n",
        "t−2\n",
        "\t​\n",
        "\n",
        "+⋯+ϵ\n",
        "t\n",
        "\t​\n",
        "\n",
        "\n",
        "Application:\n",
        "\n",
        "Good for data with temporal correlation (past values strongly influence future).\n",
        "\n",
        "Example: Stock prices depending on previous day’s values.\n",
        "\n",
        "2. MA (Moving Average Model)\n",
        "\n",
        "Structure:\n",
        "\n",
        "Current value depends on past error terms (noise).\n",
        "\n",
        "𝑌\n",
        "𝑡\n",
        "=\n",
        "𝑐\n",
        "+\n",
        "𝜃\n",
        "1\n",
        "𝜖\n",
        "𝑡\n",
        "−\n",
        "1\n",
        "+\n",
        "𝜃\n",
        "2\n",
        "𝜖\n",
        "𝑡\n",
        "−\n",
        "2\n",
        "+\n",
        "⋯\n",
        "+\n",
        "𝜖\n",
        "𝑡\n",
        "Y\n",
        "t\n",
        "\t​\n",
        "\n",
        "=c+θ\n",
        "1\n",
        "\t​\n",
        "\n",
        "ϵ\n",
        "t−1\n",
        "\t​\n",
        "\n",
        "+θ\n",
        "2\n",
        "\t​\n",
        "\n",
        "ϵ\n",
        "t−2\n",
        "\t​\n",
        "\n",
        "+⋯+ϵ\n",
        "t\n",
        "\t​\n",
        "\n",
        "\n",
        "Application:\n",
        "\n",
        "Suitable when random shocks (residuals) affect future values.\n",
        "\n",
        "Example: Demand forecasting influenced by random market fluctuations.\n",
        "\n",
        "3. ARIMA (Autoregressive Integrated Moving Average)\n",
        "\n",
        "Structure:\n",
        "\n",
        "Combines AR + differencing (I) + MA.\n",
        "\n",
        "Notation: ARIMA(p, d, q)\n",
        "\n",
        "p = AR terms\n",
        "\n",
        "d = differencing order (to remove trend, make stationary)\n",
        "\n",
        "q = MA terms\n",
        "\n",
        "Application:\n",
        "\n",
        "General-purpose model for non-stationary series with trend.\n",
        "\n",
        "Example: Forecasting sales data with upward trend.\n",
        "\n",
        "4. SARIMA (Seasonal ARIMA)\n",
        "\n",
        "Structure:\n",
        "\n",
        "Extends ARIMA by adding seasonal components.\n",
        "\n",
        "Notation: SARIMA(p, d, q)(P, D, Q, m)\n",
        "\n",
        "(P, D, Q) = seasonal AR, I, MA terms\n",
        "\n",
        "m = seasonal period (e.g., 12 for monthly data with yearly seasonality)\n",
        "\n",
        "Application:\n",
        "\n",
        "Suitable for time series with seasonality.\n",
        "\n",
        "Example: Monthly airline passenger data (seasonal peak in holidays).\n",
        "\n",
        "5. SARIMAX (Seasonal ARIMA with Exogenous Variables)\n",
        "\n",
        "Structure:\n",
        "\n",
        "SARIMA + allows inclusion of external/exogenous variables (X).\n",
        "\n",
        "Equation includes predictors besides the time series itself.\n",
        "\n",
        "Application:\n",
        "\n",
        "Best when external factors influence the series.\n",
        "\n",
        "Example:\n",
        "\n",
        "Forecasting sales considering holidays, marketing spend, or economic indicators.\n",
        "\n",
        "Energy demand prediction using weather variables.\n",
        "\n",
        "✅ Summary Table\n",
        "Model\tStructure\tHandles Trend?\tHandles Seasonality?\tAllows External Factors?\tExample Use Case\n",
        "AR\tPast values (lags)\tNo\tNo\tNo\tStock prices\n",
        "MA\tPast errors\tNo\tNo\tNo\tRandom shocks in demand\n",
        "ARIMA\tAR + Differencing + MA\tYes\tNo\tNo\tSales with trend\n",
        "SARIMA\tARIMA + Seasonal terms\tYes\tYes\tNo\tAirline passengers\n",
        "SARIMAX\tSARIMA + Exogenous variables\tYes\tYes\tYes\tSales with holidays/ads"
      ],
      "metadata": {
        "id": "oL2XpObgdma-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Dataset:\n",
        "● NYC Taxi Fare Data\n",
        "● AirPassengers Dataset\n",
        "Question 6: Load a time series dataset (e.g., AirPassengers), plot the original series,\n",
        "and decompose it into trend, seasonality, and residual component\n",
        "\n",
        "Here’s the AirPassengers dataset decomposition:\n",
        "\n",
        "Original series (blue): Monthly airline passenger counts.\n",
        "\n",
        "Trend (red): Long-term upward movement in passenger numbers.\n",
        "\n",
        "Seasonality (green): Repeating yearly fluctuations (e.g., peaks during certain months).\n",
        "\n",
        "Residuals (orange): Random variations not explained by trend or seasonality.\n",
        "\n",
        "✅ This visualization helps us separate the components for better forecasting with models like SARIMA."
      ],
      "metadata": {
        "id": "FHgx3p-HeC4M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "7: Apply Isolation Forest on a numerical dataset (e.g., NYC Taxi Fare) to\n",
        "detect anomalies. Visualize the anomalies on a 2D scatter plot.\n",
        "\n",
        "Generate a synthetic taxi fare dataset (features: distance and fare).\n",
        "\n",
        "Apply Isolation Forest to detect anomalies.\n",
        "\n",
        "Visualize the anomalies in a 2D scatter plot.\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.ensemble import IsolationForest\n",
        "\n",
        "# 1. Generate synthetic taxi fare dataset\n",
        "np.random.seed(42)\n",
        "n_samples = 300\n",
        "\n",
        "# Normal data: fare roughly proportional to distance\n",
        "distance = np.random.uniform(0.5, 20, n_samples)\n",
        "fare = distance * 2.5 + np.random.normal(0, 2, n_samples)\n",
        "\n",
        "# Add anomalies: unrealistic fares\n",
        "anomalous_distance = np.random.uniform(5, 20, 10)\n",
        "anomalous_fare = np.random.uniform(50, 150, 10)\n",
        "\n",
        "# Combine\n",
        "X = np.vstack((\n",
        "    np.column_stack((distance, fare)),\n",
        "    np.column_stack((anomalous_distance, anomalous_fare))\n",
        "))\n",
        "df = pd.DataFrame(X, columns=[\"distance\", \"fare\"])\n",
        "\n",
        "# 2. Apply Isolation Forest\n",
        "iso = IsolationForest(contamination=0.03, random_state=42)\n",
        "df[\"anomaly\"] = iso.fit_predict(df[[\"distance\", \"fare\"]])\n",
        "\n",
        "# 3. Visualize\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.scatter(df[\"distance\"], df[\"fare\"], c=df[\"anomaly\"], cmap=\"coolwarm\", marker=\"o\")\n",
        "plt.xlabel(\"Distance (miles)\")\n",
        "plt.ylabel(\"Fare ($)\")\n",
        "plt.title(\"Isolation Forest - NYC Taxi Fare Anomaly Detection\")\n",
        "plt.colorbar(label=\"Anomaly (1=normal, -1=anomaly)\")\n",
        "plt.show()\n",
        "\n",
        "\n",
        "🔎 Explanation:\n",
        "\n",
        "Normal points (1) follow a linear relation between distance and fare.\n",
        "\n",
        "Anomalies (-1) are fares too high/low compared to distance.\n",
        "\n",
        "This helps flag suspicious taxi rides (e.g., overcharging)."
      ],
      "metadata": {
        "id": "S_Kjdy_Zf32j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "8: Train a SARIMA model on the monthly airline passengers dataset.\n",
        "Forecast the next 12 months and visualize the results.\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
        "from statsmodels.tsa.seasonal import seasonal_decompose\n",
        "import statsmodels.api as sm\n",
        "\n",
        "# -------------------------------\n",
        "# 1. Load the dataset\n",
        "# -------------------------------\n",
        "# AirPassengers dataset is often available in R, so we can use statsmodels datasets\n",
        "data = sm.datasets.get_rdataset(\"AirPassengers\").data\n",
        "\n",
        "# The dataset has 'time' as index and 'value' as passengers\n",
        "data['Month'] = pd.date_range(start='1949-01', periods=len(data), freq='M')\n",
        "data.set_index('Month', inplace=True)\n",
        "ts = data['value']\n",
        "\n",
        "# -------------------------------\n",
        "# 2. Visualize the time series\n",
        "# -------------------------------\n",
        "plt.figure(figsize=(10,4))\n",
        "plt.plot(ts, label=\"AirPassengers\")\n",
        "plt.title(\"Monthly Airline Passengers\")\n",
        "plt.xlabel(\"Year\")\n",
        "plt.ylabel(\"Passengers\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# -------------------------------\n",
        "# 3. Decompose the series\n",
        "# -------------------------------\n",
        "decomposition = seasonal_decompose(ts, model='multiplicative', period=12)\n",
        "decomposition.plot()\n",
        "plt.show()\n",
        "\n",
        "# -------------------------------\n",
        "# 4. Train SARIMA model\n",
        "# -------------------------------\n",
        "# SARIMA(p,d,q)(P,D,Q,s)\n",
        "# Let's start with SARIMA(1,1,1)(1,1,1,12)\n",
        "model = SARIMAX(ts, order=(1,1,1), seasonal_order=(1,1,1,12))\n",
        "results = model.fit(disp=False)\n",
        "\n",
        "print(results.summary())\n",
        "\n",
        "# -------------------------------\n",
        "# 5. Forecast next 12 months\n",
        "# -------------------------------\n",
        "forecast = results.get_forecast(steps=12)\n",
        "forecast_mean = forecast.predicted_mean\n",
        "forecast_ci = forecast.conf_int()\n",
        "\n",
        "# -------------------------------\n",
        "# 6. Visualization\n",
        "# -------------------------------\n",
        "plt.figure(figsize=(10,5))\n",
        "plt.plot(ts, label=\"Observed\")\n",
        "plt.plot(forecast_mean.index, forecast_mean, label=\"Forecast\", color=\"red\")\n",
        "plt.fill_between(forecast_ci.index,\n",
        "                 forecast_ci.iloc[:, 0],\n",
        "                 forecast_ci.iloc[:, 1], color=\"pink\", alpha=0.3)\n",
        "\n",
        "plt.title(\"SARIMA Forecast - Next 12 Months\")\n",
        "plt.xlabel(\"Year\")\n",
        "plt.ylabel(\"Passengers\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "📊 Explanation of Steps\n",
        "\n",
        "Load dataset – The AirPassengers dataset contains monthly totals of international airline passengers from 1949–1960.\n",
        "\n",
        "Plot original series – To see overall growth and seasonality.\n",
        "\n",
        "Decompose – Splits into trend, seasonality, and residuals.\n",
        "\n",
        "SARIMA model – Combines ARIMA with seasonality (s=12 months).\n",
        "\n",
        "Example used: (p,d,q) = (1,1,1) and (P,D,Q,12) = (1,1,1,12).\n",
        "\n",
        "Forecasting – Predicts the next 12 months.\n",
        "\n",
        "Visualization – Forecast shown with confidence intervals.\n"
      ],
      "metadata": {
        "id": "F302aoMigJof"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "9: Apply Local Outlier Factor (LOF) on any numerical dataset to detect\n",
        "anomalies and visualize them using matplotlib.\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.neighbors import LocalOutlierFactor\n",
        "from sklearn.datasets import make_blobs\n",
        "\n",
        "# -------------------------------\n",
        "# 1. Generate synthetic dataset\n",
        "# -------------------------------\n",
        "X, _ = make_blobs(n_samples=300, centers=1, cluster_std=0.60, random_state=42)\n",
        "\n",
        "# Add some outliers manually\n",
        "rng = np.random.RandomState(42)\n",
        "X_outliers = rng.uniform(low=-6, high=6, size=(20, 2))\n",
        "X = np.vstack([X, X_outliers])\n",
        "\n",
        "# -------------------------------\n",
        "# 2. Apply Local Outlier Factor\n",
        "# -------------------------------\n",
        "lof = LocalOutlierFactor(n_neighbors=20, contamination=0.05)\n",
        "y_pred = lof.fit_predict(X)\n",
        "# -1 = anomaly, 1 = inlier\n",
        "scores = lof.negative_outlier_factor_\n",
        "\n",
        "# -------------------------------\n",
        "# 3. Visualization\n",
        "# -------------------------------\n",
        "plt.figure(figsize=(8,6))\n",
        "\n",
        "# Plot inliers\n",
        "plt.scatter(X[y_pred==1, 0], X[y_pred==1, 1],\n",
        "            c='blue', label='Inliers', s=40)\n",
        "\n",
        "# Plot outliers\n",
        "plt.scatter(X[y_pred==-1, 0], X[y_pred==-1, 1],\n",
        "            c='red', label='Outliers', s=60, edgecolors='k')\n",
        "\n",
        "plt.title(\"Local Outlier Factor (LOF) Anomaly Detection\")\n",
        "plt.xlabel(\"Feature 1\")\n",
        "plt.ylabel(\"Feature 2\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "📊 Explanation\n",
        "\n",
        "Dataset:\n",
        "\n",
        "Generated a blob-shaped cluster (normal points).\n",
        "\n",
        "Added random noise points (outliers).\n",
        "\n",
        "Local Outlier Factor (LOF):\n",
        "\n",
        "Works by comparing the local density of a point to its neighbors.\n",
        "\n",
        "If density is much lower → marked as an outlier.\n",
        "\n",
        "Visualization:\n",
        "\n",
        "Blue = inliers\n",
        "\n",
        "Red = anomalies"
      ],
      "metadata": {
        "id": "xB1XwniugyIK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "10: You are working as a data scientist for a power grid monitoring company.\n",
        "Your goal is to forecast energy demand and also detect abnormal spikes or drops in\n",
        "real-time consumption data collected every 15 minutes. The dataset includes features\n",
        "like timestamp, region, weather conditions, and energy usage.\n",
        "Explain your real-time data science workflow:\n",
        "● How would you detect anomalies in this streaming data (Isolation Forest / LOF /\n",
        "DBSCAN)?\n",
        "● Which time series model would you use for short-term forecasting (ARIMA /\n",
        "SARIMA / SARIMAX)?\n",
        "● How would you validate and monitor the performance over time?\n",
        "● How would this solution help business decisions or operations?\n",
        "\n",
        "⚡ Real-Time Energy Demand Forecasting & Anomaly Detection Workflow\n",
        "1. Anomaly Detection in Streaming Data\n",
        "\n",
        "Since the dataset is high-frequency (every 15 minutes) and includes contextual features (region, weather, etc.), the anomaly detection system should handle both point anomalies (sudden spikes/drops) and contextual anomalies (e.g., normal usage at night but abnormal in the afternoon).\n",
        "\n",
        "Isolation Forest\n",
        "\n",
        "Scales well to large streaming data.\n",
        "\n",
        "Detects unusual consumption by recursively partitioning data.\n",
        "\n",
        "Works well for high-dimensional inputs (usage + weather + region).\n",
        "\n",
        "LOF (Local Outlier Factor)\n",
        "\n",
        "Useful for density-based anomalies (e.g., a point that is far from its local neighborhood).\n",
        "\n",
        "More sensitive to local behavior, but not as scalable in real-time streaming.\n",
        "\n",
        "DBSCAN\n",
        "\n",
        "Can detect clusters of normal consumption vs. anomalies.\n",
        "\n",
        "Less efficient for continuous streaming unless used in mini-batch mode.\n",
        "\n",
        "👉 Choice: Use Isolation Forest for real-time detection due to scalability and robustness, and possibly supplement with LOF in batch mode for fine-grained anomaly detection.\n",
        "\n",
        "2. Short-Term Forecasting Model\n",
        "\n",
        "We need to forecast energy demand in the next few hours/days (short-term load forecasting).\n",
        "\n",
        "ARIMA – Handles trends but not seasonality well.\n",
        "\n",
        "SARIMA – Good for seasonality (daily/weekly demand cycles).\n",
        "\n",
        "SARIMAX – Best choice here because it allows exogenous features (temperature, weather, holidays, region effects).\n",
        "\n",
        "👉 Choice: SARIMAX for accurate short-term forecasts, since weather and region strongly affect energy usage.\n",
        "\n",
        "3. Validation & Monitoring\n",
        "\n",
        "Validation\n",
        "\n",
        "Use train-test split with rolling windows to mimic real-time forecasting.\n",
        "\n",
        "Metrics:\n",
        "\n",
        "MAE / RMSE for forecasting accuracy.\n",
        "\n",
        "Precision/Recall/F1 for anomaly detection (based on labeled anomalies, if available).\n",
        "\n",
        "Monitoring in Production\n",
        "\n",
        "Track forecast error drift over time.\n",
        "\n",
        "Implement model retraining triggers (e.g., if forecast error > threshold for several days).\n",
        "\n",
        "Use a dashboard (Grafana / Kibana) for real-time visualization of consumption, forecast, and anomaly alerts.\n",
        "\n",
        "4. Business Value / Operational Impact\n",
        "\n",
        "Load Balancing & Grid Stability\n",
        "\n",
        "Forecasting helps schedule power generation and avoid blackouts.\n",
        "\n",
        "Anomaly detection prevents overloads caused by unexpected spikes.\n",
        "\n",
        "Cost Optimization\n",
        "\n",
        "Helps energy providers buy/sell electricity in the market at optimal times.\n",
        "\n",
        "Reduces penalties for demand-supply mismatch.\n",
        "\n",
        "Preventive Maintenance\n",
        "\n",
        "Abnormal drops might indicate faults in sensors or grid failures → quick maintenance response.\n",
        "\n",
        "Customer Insights\n",
        "\n",
        "Detect unusual consumption in specific regions to optimize energy distribution and demand-response programs.\n",
        "\n",
        "✅ Final Workflow Summary:\n",
        "\n",
        "Streaming data ingestion → feature engineering (lag features, weather) → Isolation Forest for anomaly detection → SARIMAX for short-term forecasts → real-time monitoring dashboards → feedback loop for retraining → business decision support (load balancing, cost saving, maintenance)."
      ],
      "metadata": {
        "id": "rte0ZLn9hAUS"
      }
    }
  ]
}